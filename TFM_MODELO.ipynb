{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97078be3-b263-433c-a666-d2ae414d6134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/Alberto Navarro/.cache/huggingface/datasets/csv/default-6a4239bfa2cf3f73/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 995.80it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.24it/s]\n",
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/Alberto Navarro/.cache/huggingface/datasets/csv/default-6a4239bfa2cf3f73/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv', data_files='data_small_train.csv')\n",
    "\n",
    "#dataset = load_dataset(train_dc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0a5b1ba-e535-40b9-9a80-13c0e224d08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'TARGET', 'FECHA_STRING', 'COMENTARIO', 'COMENTARIO_LIMPIO', 'PALABRAS', 'TOKENS', 'NUM_TOKENS', 'sentimiento', 'comentario_tarea'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3cb30a8a-7c2b-4421-b735-26c71d3ded19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "def train_test_split(dataset_dict: DatasetDict, test_size: float = 0.2) -> DatasetDict:\n",
    "    \"\"\"Split a dataset dictionary into train and test based on test size.\n",
    "\n",
    "    Args:\n",
    "        dataset_dict (DatasetDict): Input dataset dictionary.\n",
    "        test_size (float, optional): Fraction of data to include in the test set. Defaults to 0.2.\n",
    "\n",
    "    Returns:\n",
    "        DatasetDict: Result dataset dictionary with the desired splitting strategy.\n",
    "    \"\"\"\n",
    "    train_test = dataset_dict[\"train\"].train_test_split(test_size=test_size)\n",
    "\n",
    "    return DatasetDict({\n",
    "        \"train\": train_test[\"train\"],\n",
    "        \"test\": train_test[\"test\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0113b482-58fe-4bed-97cc-ffd450678ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de la función para dividir un DatasetDict en train y test\n",
    "divided_data = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "648f8bcd-46ab-40b1-ab6d-95afc7b65b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\Alberto Navarro\\.cache\\huggingface\\datasets\\csv\\default-6a4239bfa2cf3f73\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0b57310459c7b36a.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\Alberto Navarro\\.cache\\huggingface\\datasets\\csv\\default-6a4239bfa2cf3f73\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-bd31e962806a74f0.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset_train_dataset = divided_data[\"train\"].shuffle(seed=42).select([i for i in list(range(100))])\n",
    "dataset_test_dataset = divided_data[\"test\"].shuffle(seed=42).select([i for i in list(range(10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7e79b9b4-3e3b-4690-831d-f70180419aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_dict({ \n",
    "    \"text\": dataset_train_dataset[\"COMENTARIO_LIMPIO\"], # Campo de texto \n",
    "    \"label\": dataset_train_dataset[\"TARGET\"] # Campo de sentimiento\n",
    "})\n",
    "\n",
    "test_ds = Dataset.from_dict({ \n",
    "    \"text\": dataset_test_dataset[\"COMENTARIO_LIMPIO\"], # Campo de texto \n",
    "    \"label\": dataset_test_dataset[\"TARGET\"] # Campo de sentimiento\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "121b2849-5c31-4558-a68d-f6547e5c8faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d76111-5258-4325-91a6-33dd64d78af7",
   "metadata": {},
   "source": [
    "### Fine tuning al modelo pre entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "42f77a26-4dd1-4a3b-b5e4-01c874fc0a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "#tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6cdff59f-07ef-4e21-a2d6-c67f2b9e5886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "   return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=64) #padding=True\n",
    " \n",
    "tokenized_train = train_ds.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "fc65ef91-99b8-44d2-adea-525ead66729f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d230e3bc-5156-480c-bb4c-2f73ea927c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "4a6e0f9b-3d1a-4e61-8592-500465ed02e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "cbdca395-aadc-4960-a3ee-d2b85338a3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "cf5cb356-44f3-4162-8fc3-ec24a2ff71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d1fbe12c-c98f-4d4a-a1ac-123fce5c0540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=T5Tokenizer(name_or_path='google/flan-t5-small', vocab_size=32100, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "162bb785-8688-4061-99c7-32905bf8f61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at google/flan-t5-small and are newly initialized: ['classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(\"t5-small\", num_labels=2)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google/flan-t5-small\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "53bb8dd7-1450-487f-b61a-4a52695c6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "  \n",
    "   logits, labels = eval_pred\n",
    "   print(logits)\n",
    "   print(labels)\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "   return {\"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "fc73c3b2-cdde-4273-aaf7-2104cad57387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    load_f1 = load_metric(\"f1\")\n",
    "    \n",
    "    # Desempaquetar los valores de la tupla\n",
    "    labels = eval_pred.label_ids\n",
    "    preds = eval_pred.predictions.argmax(-1)\n",
    "    # Calcular el F1-score\n",
    "    f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "    \n",
    "    return {\"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "fb1f4912-a62a-4c10-9ab3-354806a09d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    " \n",
    "repo_name = \"finetuning-sentiment-model-3000-samples\"\n",
    " \n",
    "training_args = TrainingArguments(\n",
    "   output_dir=repo_name,\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=2,\n",
    "   weight_decay=0.01,\n",
    "   save_strategy=\"epoch\",\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_train,#tokenized_train\n",
    "   eval_dataset=tokenized_test,#tokenized_test\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "7ea409b0-366f-44e9-be25-eb17120d53c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "2f5e4554-b57f-4d2e-ad70-15a692359d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = trainer.train_dataset\n",
    "eval_dataset = trainer.eval_dataset\n",
    "cm = trainer.compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "9115fafc-a902-40bd-b694-091914e9ec87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "6d0fccc0-0063-4b65-a5f7-5888dd57e2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Death disco amazing Smangled x',\n",
       " 'label': 1,\n",
       " 'input_ids': [12358,\n",
       "  5025,\n",
       "  32,\n",
       "  1237,\n",
       "  180,\n",
       "  51,\n",
       "  19834,\n",
       "  3,\n",
       "  226,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "eb157d0d-184e-4937-815a-b5dec79578eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6/14 00:48 < 01:37, 0.08 it/s, Epoch 0.71/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[365], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\Lib\\site-packages\\transformers\\trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\Lib\\site-packages\\transformers\\trainer.py:1837\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1834\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1836\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1837\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1840\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1842\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1843\u001b[0m ):\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1845\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\Lib\\site-packages\\transformers\\trainer.py:2693\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   2692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2693\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\Lib\\site-packages\\accelerate\\accelerator.py:1985\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   1983\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1985\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "ed9036cf-850b-41fb-9e51-9a6f72d15766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.15083723, 0.48156506],\n",
      "       [0.21024026, 0.56997645],\n",
      "       [0.0354127 , 0.49313873],\n",
      "       [0.08557307, 0.5560947 ],\n",
      "       [0.17644835, 0.5209846 ],\n",
      "       [0.03333851, 0.5483879 ],\n",
      "       [0.12620753, 0.5867075 ],\n",
      "       [0.18800125, 0.4190094 ],\n",
      "       [0.16385531, 0.45390055],\n",
      "       [0.13604286, 0.46245793]], dtype=float32), array([[[ 1.08796395e-02, -9.52283293e-02, -5.31933904e-02, ...,\n",
      "          9.26067680e-02,  5.24565503e-02,  1.82792917e-02],\n",
      "        [ 9.54191945e-03, -1.07318364e-01, -2.10455358e-01, ...,\n",
      "          5.51800318e-02, -2.14922503e-01,  7.66242370e-02],\n",
      "        [-9.66642201e-02, -7.85706565e-02, -1.55693069e-01, ...,\n",
      "          1.65006578e-01,  4.35043946e-02, -1.27334064e-02],\n",
      "        ...,\n",
      "        [ 7.11672083e-02, -2.24442720e-01,  5.49522368e-03, ...,\n",
      "         -3.18226278e-01, -4.66227904e-02,  1.51638128e-02],\n",
      "        [ 7.11672083e-02, -2.24442720e-01,  5.49522368e-03, ...,\n",
      "         -3.18226278e-01, -4.66227904e-02,  1.51638128e-02],\n",
      "        [ 7.11672083e-02, -2.24442720e-01,  5.49522368e-03, ...,\n",
      "         -3.18226278e-01, -4.66227904e-02,  1.51638128e-02]],\n",
      "\n",
      "       [[ 1.05277829e-01, -1.87880501e-01, -1.15221716e-01, ...,\n",
      "         -9.03629661e-02,  1.20634481e-01, -1.01339154e-01],\n",
      "        [-1.58963574e-03, -8.51445273e-03, -6.47827424e-03, ...,\n",
      "         -1.14642335e-02, -7.08611077e-03,  1.59385666e-01],\n",
      "        [-1.01443663e-01, -1.37770131e-01, -1.48768164e-02, ...,\n",
      "         -5.31580225e-02, -2.79550366e-02, -2.23609000e-01],\n",
      "        ...,\n",
      "        [ 3.98135409e-02, -1.44570082e-01, -8.77432823e-02, ...,\n",
      "         -2.76849419e-01, -1.51927784e-01, -1.53380066e-01],\n",
      "        [ 3.98135409e-02, -1.44570082e-01, -8.77432823e-02, ...,\n",
      "         -2.76849419e-01, -1.51927784e-01, -1.53380066e-01],\n",
      "        [ 3.98135409e-02, -1.44570082e-01, -8.77432823e-02, ...,\n",
      "         -2.76849419e-01, -1.51927784e-01, -1.53380066e-01]],\n",
      "\n",
      "       [[-7.15374423e-04, -9.95414425e-03, -5.03438152e-03, ...,\n",
      "         -6.04104204e-03, -8.08829162e-03,  1.61728680e-01],\n",
      "        [ 3.31610925e-02, -1.53757721e-01, -5.81276827e-02, ...,\n",
      "         -2.58654281e-02,  6.23994274e-03, -2.09939778e-02],\n",
      "        [ 5.00791110e-02, -7.09424019e-02,  1.62444845e-01, ...,\n",
      "         -1.18951246e-01, -9.11070481e-02, -6.45502433e-02],\n",
      "        ...,\n",
      "        [-1.57304227e-01, -2.34799221e-01,  7.13072494e-02, ...,\n",
      "          4.35424261e-02, -1.08524792e-01,  3.96109261e-02],\n",
      "        [-1.57304227e-01, -2.34799221e-01,  7.13072494e-02, ...,\n",
      "          4.35424261e-02, -1.08524792e-01,  3.96109261e-02],\n",
      "        [-1.57304227e-01, -2.34799221e-01,  7.13072494e-02, ...,\n",
      "          4.35424261e-02, -1.08524792e-01,  3.96109261e-02]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 5.66583052e-02,  4.37150989e-03,  2.45604724e-01, ...,\n",
      "         -2.00787961e-01,  8.56804326e-02, -5.08746654e-02],\n",
      "        [-2.98023429e-02, -1.48872912e-01,  6.59585223e-02, ...,\n",
      "         -1.52123854e-01,  1.11297704e-01, -1.11973263e-01],\n",
      "        [ 8.11978988e-03, -1.59460589e-01, -8.48528966e-02, ...,\n",
      "         -2.00051084e-01,  1.44765317e-01, -8.90687406e-02],\n",
      "        ...,\n",
      "        [ 3.60658579e-02, -1.74251154e-01, -1.80502653e-01, ...,\n",
      "         -2.31083184e-01, -4.74961735e-02, -1.60221737e-02],\n",
      "        [ 3.47625129e-02, -1.77771658e-01, -1.65304720e-01, ...,\n",
      "         -2.25171268e-01, -6.01762310e-02, -2.01056991e-02],\n",
      "        [ 2.87850648e-02, -1.71463132e-01, -1.51880801e-01, ...,\n",
      "         -2.13068932e-01, -5.47600985e-02, -2.21062005e-02]],\n",
      "\n",
      "       [[-7.96557963e-02, -2.82203376e-01,  3.02734315e-01, ...,\n",
      "         -1.04194939e-01,  1.03564613e-01, -1.57236785e-01],\n",
      "        [-2.66134478e-02, -2.19898876e-02,  6.01256685e-03, ...,\n",
      "          7.84852263e-03, -3.32887173e-02,  1.59876958e-01],\n",
      "        [-2.20981359e-01, -1.12779075e-02,  1.38529927e-01, ...,\n",
      "          7.32251182e-02, -1.24184556e-01, -1.23455070e-01],\n",
      "        ...,\n",
      "        [ 2.43511968e-04, -7.69977644e-02, -7.00596124e-02, ...,\n",
      "          6.08345531e-02, -3.86943370e-02, -1.94023892e-01],\n",
      "        [ 1.35767199e-02, -7.66205639e-02, -1.07123241e-01, ...,\n",
      "          5.69141284e-02, -2.97508221e-02, -1.79327309e-01],\n",
      "        [ 1.56699624e-02, -8.43601078e-02, -1.17333487e-01, ...,\n",
      "          4.90074046e-02, -2.48296056e-02, -1.80328637e-01]],\n",
      "\n",
      "       [[-3.82250233e-04, -7.60309398e-03, -4.57184343e-03, ...,\n",
      "         -1.00046638e-02, -4.77060722e-03,  1.60005748e-01],\n",
      "        [ 3.68759297e-02, -5.91574982e-02,  1.11614920e-01, ...,\n",
      "         -8.65300670e-02,  7.91974142e-02, -9.83904153e-02],\n",
      "        [ 1.58555806e-02, -2.64717788e-02,  1.27443075e-01, ...,\n",
      "          6.02896065e-02,  1.52732268e-01, -6.95147291e-02],\n",
      "        ...,\n",
      "        [ 3.33803184e-02, -2.30047271e-01,  4.52338066e-03, ...,\n",
      "         -2.90444195e-01, -7.94539303e-02, -1.53754786e-01],\n",
      "        [ 3.33803184e-02, -2.30047271e-01,  4.52338066e-03, ...,\n",
      "         -2.90444195e-01, -7.94539303e-02, -1.53754786e-01],\n",
      "        [ 3.33803184e-02, -2.30047271e-01,  4.52338066e-03, ...,\n",
      "         -2.90444195e-01, -7.94539303e-02, -1.53754786e-01]]],\n",
      "      dtype=float32))\n",
      "[1 0 1 1 1 1 1 1 0 1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 10) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[368], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\Lib\\site-packages\\transformers\\trainer.py:2972\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   2969\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   2971\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 2972\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2973\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2975\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   2976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   2977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2982\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   2983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\Lib\\site-packages\\transformers\\trainer.py:3261\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3257\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[0;32m   3258\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[0;32m   3259\u001b[0m         )\n\u001b[0;32m   3260\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3261\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3263\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[366], line 10\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(eval_pred)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels)\n\u001b[1;32m---> 10\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m f1 \u001b[38;5;241m=\u001b[39m load_f1\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpredictions, references\u001b[38;5;241m=\u001b[39mlabels)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:56\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:45\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(asarray(obj), method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 10) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "71d36a7f-dd82-4d26-ad18-c36f27f277e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'numpy=1.21.6'\n",
      "Hint: = is not a valid operator. Did you mean == ?\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy=1.21.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2ef8d-a4d4-4c7b-a126-75ae5e38a7b7",
   "metadata": {},
   "source": [
    "### Modelo pre entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "2a14420a-6f8a-4938-8293-a8cf0f09edfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Alberto Navarro/.cache/huggingface/datasets/csv/default-6a4239bfa2cf3f73/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv', data_files='data_small_train.csv')\n",
    "\n",
    "#dataset = load_dataset(train_dc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "5182c04e-53f4-46bb-b8f3-49fbee69c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "def train_test_split(dataset_dict: DatasetDict, test_size: float = 0.2) -> DatasetDict:\n",
    "    \"\"\"Split a dataset dictionary into train and test based on test size.\n",
    "\n",
    "    Args:\n",
    "        dataset_dict (DatasetDict): Input dataset dictionary.\n",
    "        test_size (float, optional): Fraction of data to include in the test set. Defaults to 0.2.\n",
    "\n",
    "    Returns:\n",
    "        DatasetDict: Result dataset dictionary with the desired splitting strategy.\n",
    "    \"\"\"\n",
    "    train_test = dataset_dict[\"train\"].train_test_split(test_size=test_size)\n",
    "\n",
    "    return DatasetDict({\n",
    "        \"train\": train_test[\"train\"],\n",
    "        \"test\": train_test[\"test\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "b83bed0e-949d-4532-9d86-81bf6a51763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\Alberto Navarro\\.cache\\huggingface\\datasets\\csv\\default-6a4239bfa2cf3f73\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-acf047cc63c258dd.arrow and C:\\Users\\Alberto Navarro\\.cache\\huggingface\\datasets\\csv\\default-6a4239bfa2cf3f73\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-d9743f5f584f4349.arrow\n"
     ]
    }
   ],
   "source": [
    "# Uso de la función para dividir un DatasetDict en train y test\n",
    "divided_data = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b222039a-6b16-4596-81ee-92defeb61a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\Alberto Navarro\\.cache\\huggingface\\datasets\\csv\\default-6a4239bfa2cf3f73\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0b57310459c7b36a.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\Alberto Navarro\\.cache\\huggingface\\datasets\\csv\\default-6a4239bfa2cf3f73\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-bd31e962806a74f0.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset_train_dataset = divided_data[\"train\"].shuffle(seed=42).select([i for i in list(range(100))])\n",
    "dataset_test_dataset = divided_data[\"test\"].shuffle(seed=42).select([i for i in list(range(10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "9ecbddab-7ae3-4be6-a89a-062b8f76c54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "   return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=64) #padding=True\n",
    " \n",
    "tokenized_train = train_ds.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "74ef843e-5d9f-49da-be5e-4265648c648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_with_labels = []\n",
    "\n",
    "for i in range(len(tokenized_train)):\n",
    "    text = tokenized_train[i][\"text\"]\n",
    "    label = tokenized_train[i][\"label\"]\n",
    "    texts_with_labels.append({\"text\": text, \"sentiment\": label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "9b138c91-bded-4707-a059-37062be5f546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'icg979 hows your summer so far ', 'sentiment': 1},\n",
       " {'text': 'Happy Mothers Day to All the moms and to Those that have Moms That means Happy Mothers Day EVeryONe ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Hes Just Not That Into You Hate ', 'sentiment': 0},\n",
       " {'text': 'The queen has left the building I did some cleaning Ironing is done now too ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'why I can hear its quotjustquot 86ÂF noooo its 915ÂF ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'IAmAlexSuavez i added sumthing ', 'sentiment': 1},\n",
       " {'text': 'One of my new friends just left ', 'sentiment': 0},\n",
       " {'text': 'Good morning ', 'sentiment': 1},\n",
       " {'text': 'Up early because of the time difference Going for a walk with my new Canon 450D ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'I just got flowers ', 'sentiment': 1},\n",
       " {'text': '15 days to golast week of work ', 'sentiment': 0},\n",
       " {'text': 'Stay tuned for more info on this years performers You are in for a pleasant surprise ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'westhgate Shame about your job have you thought about working for yourself theres big money to be paid httpbitly1864ml',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Sooo haaard I got headache for this test I want its over soon',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Why cant I see WHITE SOX players random bars I go to NOT Cubs players waaah',\n",
       "  'sentiment': 0},\n",
       " {'text': 'colocelt Ah nice to meet you Eric eSquared82 I will just call you E2 for short ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'mitten79 colin punctured ', 'sentiment': 0},\n",
       " {'text': 'Going to do some work for my m8 look at the sky and realise how small u are ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'mrskutcher nice clutch ', 'sentiment': 1},\n",
       " {'text': 'meglyn what a lame way of using a sick day ', 'sentiment': 0},\n",
       " {'text': 'Falling in love with Josh Hartnett all over again Watching him on Star Movies as I update this ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'newmediaguy not just pizzahand made dough slow cooked sauce all fresh ingredients Kidsll prolly say not as good as Dominos ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'getting tied up like an Escher diagram in Excel Oh what funmy brain hurts ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Working for Loreal again lots of fun ', 'sentiment': 1},\n",
       " {'text': 'anith Get 100 followers a day using wwwtweeterfollowcom Once you add everyone you are on the train or pay vip ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'even if its ACTINGit still broke my heart ', 'sentiment': 0},\n",
       " {'text': 'shaylareneee love you daughter ', 'sentiment': 1},\n",
       " {'text': 'Also follow tessacrowe StefLoc ', 'sentiment': 1},\n",
       " {'text': 'commongrind trisstephenson I need to see the Angel Coffee House too need some decent coffee near Milton Keynes ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'nessie111 Voted for ya ', 'sentiment': 1},\n",
       " {'text': 'Ben12345266 danadays haha i never subbed him either i even tried giving him a 2nd chance recentlyamp wow no yay Dana 100 followers ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'slept from 1am to 1130am still not enough I woke up because I was hungry httpplurkcompwwpig',\n",
       "  'sentiment': 0},\n",
       " {'text': 'im julia its on yelp Pho Pasteur yum yum yum ', 'sentiment': 1},\n",
       " {'text': 'says playing restaurant city httpplurkcompx5caa', 'sentiment': 1},\n",
       " {'text': 'hates packing to go back to cola ', 'sentiment': 0},\n",
       " {'text': 'xbrookecorex I live in the west but I wanna goooooooooooo',\n",
       "  'sentiment': 0},\n",
       " {'text': 'I left my bagel unattended because I had to see to my dads tantrum of the hour and my cats started eating the cream cheese ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Sadddddd ', 'sentiment': 0},\n",
       " {'text': 'Jessie x aww i hate the dentist too i have to go tommoz cos i may be getting braces S eurgh ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'With Tom ', 'sentiment': 1},\n",
       " {'text': 'nick carter of course i wanna go BUT im in Chile so far ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'elevatingslowly SIGH I miss you kiki lt3', 'sentiment': 0},\n",
       " {'text': 'Heeeey im listening now to the new single quotits alright its Oquot by ashley tisdale and it totally ROX shes awesome ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'its nice to know that my imaginary family is turning real except Im not part of it ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Heading out 4 a luau amp mai taistime 2 put on our hula skirts amp show em how we shake it in Texas ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'deadtinkerbell takin pics and postin links aye aye ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Nasty weather this week ', 'sentiment': 0},\n",
       " {'text': 'encoresara A way to avoid just talking to yourself will be to talk about some topics that might attract search hits fr kindred spirits ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'princessherb i only saw a feel heels there amp couldnt find any rings SOO angry maybe ill just get online ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'ButerLoveKwess My mom cooked it lol But noo I have a shitkick We can only get our tones from them ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'calisa flight now arrives at 1230 ', 'sentiment': 0},\n",
       " {'text': 'NOOOOOOOOOOOOOOOOO Rick Shaws the best take away joint in Edinburgh has closed Gutted',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Graduation day waiting on the family ', 'sentiment': 1},\n",
       " {'text': 'Well Im here good morningbrunchish I took my exam think I did good ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Im so annoyed I have to work on the hottest day ever ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'shaunmichaelb cooloo I want to see demi in concert like her own concert rather than supporting the jbs that sounds like a good',\n",
       "  'sentiment': 0},\n",
       " {'text': 'So tired and ready for Mexico If we still plan to go',\n",
       "  'sentiment': 0},\n",
       " {'text': 'I really hope all the charges on David for this whole mess get dropped ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'liam edwards Get 100 followers a day using wwwtweeterfollowcom Once you add everyone you are on the train or pay vip ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Looking forward to webdevfulda meetup tomorrow httpisgdM77y If youre around Join us ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'catherineLd in 4th year Uni I did an astrophysics presentation with a cat on each slide It had mixed responses',\n",
       "  'sentiment': 1},\n",
       " {'text': 'DaveJMatthews cant wait to see you in Tampa in august Dave Stop by for dinneryou aint never had my cornbread ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'i feel bad for anyone who is taking a final right now god bless ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'NotFrankIero oh well Hah You can be mad at me it wont make a difference Urgh Its not really that addicting',\n",
       "  'sentiment': 1},\n",
       " {'text': 'party in the beach ', 'sentiment': 1},\n",
       " {'text': 'im loving the heat ', 'sentiment': 1},\n",
       " {'text': 'Micherlou Thanks for recording yeah wasnt going to bother but chris got it for me ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Have to get up in 5 12 hours night all Zzzzzzz', 'sentiment': 0},\n",
       " {'text': 'lisey greasy popcorn and 5 bottles of water ', 'sentiment': 0},\n",
       " {'text': 'Just got back from Cali ', 'sentiment': 1},\n",
       " {'text': 'wants a beach day but feels like crapagain ', 'sentiment': 0},\n",
       " {'text': 'Two presidents since 1960 and the highest HDI in subsaharan Africa Cest Gabon Arrived in Oyem last night serenaded by Celine Dion ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Sitting at the piano with steph Really hungry inventing next',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Work work work and mooore work The kind of work I dont enjoy unfortunetly I wish it was coding or something ',\n",
       "  'sentiment': 0},\n",
       " {'text': ' CranberryPerson Dear hyper chihuahua we only have 45 minutes left together on this drive but I have a httptrimlAj6',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Fuzzball is more fun than Nuggets httptinyurlcomdhpol7',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Im sooooo angry ', 'sentiment': 0},\n",
       " {'text': 'is hoping today goes well Cant put up with it But I know I will ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'uselesscah or made it up works too ', 'sentiment': 1},\n",
       " {'text': 'has the illest elish polow at boro khalas she maade so much for us wow yumm ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'McFanpire Okay give it to the videos for now and then ill cheer you up to tidy up your room whilst ill be studying ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'maryse0uellet nice A little AM retail therapy ', 'sentiment': 1},\n",
       " {'text': 'chrisscross Maaan I only just noticed that you replied to me over a week ago Re Hornbeck Sorrrrrrrrrrry ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'katzeye 001 So glad I found you You gave the BEST speech Ive seen I hope you dont mind I posted it on my blog You Rock ri4dc',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Yeah I agree with all Susan Boyles fans out there She truly deserves to win BGT ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Homemade pizza in the oven ', 'sentiment': 1},\n",
       " {'text': 'No word on ultrasn0w ', 'sentiment': 0},\n",
       " {'text': 'stereophonics Happy Birthday Kelly Hope itll be a great day and tomorrow you can face the hangover ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Going to the bar any bar ', 'sentiment': 0},\n",
       " {'text': 'Me amp snookie09 and kedrickelijah is havin a good ol time wachin youtube vids ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'cant set up my phone on twitter ', 'sentiment': 0},\n",
       " {'text': 'took a math test today The day before the test the teacher says bring your calculator Luke was confident Teacher decided no calcs ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'hardlynormal soon my friend Soon ', 'sentiment': 1},\n",
       " {'text': 'Im so happy that Bosnia came on 9th place ', 'sentiment': 1},\n",
       " {'text': 'Emmett just referred to tiny blocks as requisite dudes ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'expression of the day upside down in portuguese de pernas para o ar ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Gah why does she want me to go in for four hours ', 'sentiment': 0},\n",
       " {'text': 'Freshmen Orientation done This day was a blast Feeling excited on my first day Yaay ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'have u ever liked a song soo muchbut the video kills the song 4 u yea just happend 2 me ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Boddingtons hi Princess hugs how are you ', 'sentiment': 1},\n",
       " {'text': 'my 1st twitter ', 'sentiment': 1},\n",
       " {'text': 'Talabikins Phew I though I was going to regret asking I sing as well but I actually cant Lol',\n",
       "  'sentiment': 1},\n",
       " {'text': 'NixiePixel I wish I could stop president Bush from killing so many innocent people in Iraq ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'BostonCourt we had to leave soon after unfortunately But succeded in my goal of getting my friend interested in seeing more theater ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'cant sleep so is going old school retro gaming and playing streets of rage and sonic on the sega mega drive â',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Disappointed that the new episodes of the chaser s war on everything are only streamed for viewers within Australia from now on ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'travis fulton I know its hard to say whether I was ignoring it before or if im just a hypochondriac but the tingling is real ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Ok been waiting for three hours now maybe not meant to be ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'ive been working hard since 9am but only half done ROAR',\n",
       "  'sentiment': 0},\n",
       " {'text': ' francesca thx f thats what I read online but looks like Elements doesnt allow rasterization sad velma',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Butter cream ice and lollipops Want a cold rock ', 'sentiment': 0},\n",
       " {'text': 'christine marie no my dear it is totally ubderstandable U have new loves in your life ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Heading to Port Clinton for a meeting Of course I will be making a stop at Coffee Express for my fav Andes Mocha ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'HimOverThere yeah I think Ill ask her just in case xx',\n",
       "  'sentiment': 1},\n",
       " {'text': 'quotI wonder whyquot is a fresh post on httpwwwbohica2kcom ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'skipptXG lights back up blackout for a bout an hour near mapo station ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'pisaniel yeah i def do boo freakin hoo Damn little kiddies',\n",
       "  'sentiment': 0},\n",
       " {'text': 'matthewandrew Is that from a song Its great poetry ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Grrr why is my tum misbehaving ', 'sentiment': 0},\n",
       " {'text': 'Watching Today show on NBC Why do folks in the crowd jostle to get a shot of the back of the stars heads ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'decode this email please by court912 httpunu2wn3 job php freelance',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Finally got myself a Feed 100 bag Cute bag for such a worthy cause httpbitly2NKGi',\n",
       "  'sentiment': 1},\n",
       " {'text': 'ladieslovetj im not playin if yuh ont take meh its war kid fyi im always ready so wahtcah doing now',\n",
       "  'sentiment': 1},\n",
       " {'text': 'i had video for 10 seconds and then it failed asot400',\n",
       "  'sentiment': 0},\n",
       " {'text': '17 Again was the best movie ever I think everyone should do themselves justice and go and see itFor me ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Just starting to make some illustrations for the lucky competition winners httpyfrogcom11hsbxj',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Yey im going to Curacao tomorrow Its gonna be great Ill get home on friday soooo no computer till there ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'courtneylyons yes i did but i love me the time off',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Anyone know how to install UniConverter httpisgd1cJSm into Inkscape OS X This requires unix commands or sumthin or other ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'gam going all fugly on me ', 'sentiment': 0},\n",
       " {'text': 'had a bad sleep last night and i feel like crap my throat is killing me ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'WOW Facebook ready to launch Vanity URL Im getting ready to claim facebookcomstan httptcrnch2tJ via stanleytang',\n",
       "  'sentiment': 1},\n",
       " {'text': 'dementes Intravenous coffee the answer to all lifes problems ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Numberrr2 Eh I try Have fun at the flea market Buy me something too D',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Am so tired I have a poorly twin with a fever and diahorrea ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'httpbitlycHfwj one of the best Ive seen ', 'sentiment': 1},\n",
       " {'text': 'elsienita omg thats horrible it was just in sept it happen here ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'off to the vatican to try to see the pope and prob mass in st peters WOOT finally a mass im excited to go to',\n",
       "  'sentiment': 1},\n",
       " {'text': 'piffi iM SO JEALOUS OF YOU NOW ', 'sentiment': 1},\n",
       " {'text': 'JayDabhi Bought THE tune man LOVE IT ', 'sentiment': 1},\n",
       " {'text': 'Is just testing Daylightapp And is trying to like it as much as he loves Billingsapp âÂ httpimglyLn âÂ And he cant ATM',\n",
       "  'sentiment': 0},\n",
       " {'text': 'dmiller23 Not to say he aint a pothead just does it far enough out probly to get it out of his blood b4 fights',\n",
       "  'sentiment': 1},\n",
       " {'text': 'LOL I really slept good and the ppl who wre out by 8 are actually up those that are in bed till 1 haha anyway DC was fun and ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'cvawter Thanks for the FF love I really appreciate it ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'sharlynnx aww i know what you mean gets a bit distracting then you just wanna sunbathe ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Topheratl ahh well lemme know if you hear anything For now I guess Ill be saving my work a lot more often ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'CraigTeich yes my twelve cats are inside one its even on my chair',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Ivanthecrazycat Ivan is a smart cat ', 'sentiment': 1},\n",
       " {'text': 'mrule55 dont want me time w me tear ', 'sentiment': 0},\n",
       " {'text': 'which i absolutely hate who doesnt because im not used to getting rejected hahaha ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'jakeron ok Ill check it out Thanks ', 'sentiment': 1},\n",
       " {'text': 'mimiboo YES I have 3 days off next week Week days of course but 3 days none the less ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Ok ready to go Off to see ThrillHillBruce pinkpop Wonder if Ill bump into him around oxfam novib zelfdoen headquarters onpp09',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Dude Im so glad I buckled down this morning and got this paper done so that my night is free now ltfantasyworldgt Paper times now ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Love homemade pizza movies with Tyler and the adorable lab pup Good Saturday ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'zaireenbee thanks for the tips yeen i pulun gile2 tgk practical video last night until 3 am woke up at 6 for theories skrg dh tingtong',\n",
       "  'sentiment': 1},\n",
       " {'text': 'dude my roommate got sick overnight and downed a bottle of robotussin cuz he couldnt stop coughing can you say quotROBOTRIPquot ack ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Going out with my bff LaCina ', 'sentiment': 1},\n",
       " {'text': 'is hoping pasta and chocolate cake will help her night and her little heart ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'maryepworth sounds like a great way to spend the day ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'had a good night with Chad now time to relax sleeep and sleep in Family leaves tomorrow ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'memsom ha ha cream for Oh the itching Ive got cream but I cant reach all the places Unless I make an applicator to get my back',\n",
       "  'sentiment': 0},\n",
       " {'text': 'danadearmond bring a jacket its almost summer time ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'orangepascal there are a few lastfm alts on android but most iv seen online are US only ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'I feel so bored Ooohh give me a wonderful things ', 'sentiment': 0},\n",
       " {'text': 'Yaoi415 your time is fine im not doing anything in CST anyway id rather be in the PST if you catch my drift SIGH ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'NathalieKinders hes just a guy who got drunk and said something stupid Try not to dwell on it lovie hes still seb ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Sometimes I have a pillow and sometimes I dont ', 'sentiment': 0},\n",
       " {'text': 'chikari Ari darling You make me laugh so hard te amo ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'rushad88 yeah you are lucky sighh Are you going to dubai anytime soon',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Demise DoLL No you win I could not come up with a witty reply to you telling me that I won ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'the PA system is playing the song i used for my wedding march Vivaldi httpplurkcompp71bz',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Kunngpow why not ', 'sentiment': 1},\n",
       " {'text': 'bevysmith thxs for joining the ilove movement ', 'sentiment': 1},\n",
       " {'text': 'Filmstalker read ur frostnixon review deffo gonna get that soon ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'TuMTran yes of course on and on and on we are calling out and out again ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'pilgrimfamilyuk Ill look out for you x', 'sentiment': 1},\n",
       " {'text': 'blessedAyesha cant find any electrition at this tym uwaa uwaa',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Good morning and excuse me whilst I squee after getting an atreply from Jim Lee I know it wasnt much but hes on my list of heroes ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'lose again 51 ngokk ckckck ', 'sentiment': 0},\n",
       " {'text': 'what for a funny day never had so much fun at work thx to my collegue ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Wossy i cant wait to watch your show later ', 'sentiment': 1},\n",
       " {'text': 'is going to a banquet tonightdress up time im sooo tired',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Ethnicsupplies Thanks off in a bit ', 'sentiment': 1},\n",
       " {'text': 'Jimi Hendrix rockin the fuck out of the guitar as always httpblipfm7b6ag',\n",
       "  'sentiment': 1},\n",
       " {'text': 'ririchard haha ill tell you later ', 'sentiment': 1},\n",
       " {'text': 'hannahkhymych i love betsy johnson i love her watches and jewelry cant get any of her stuff here though ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Home from the gym and I finally feel so much better Get online and talk to me bitches ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Had a great evening of champagne and beer and a little McDo antonybosschems place Great ideas cool discussions ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Omg that clip was AMAZING ', 'sentiment': 1},\n",
       " {'text': 'Having a beer getting ready to play poker ', 'sentiment': 1},\n",
       " {'text': 'Bored and kinda lonely my parents went up to the lake I didnt have a friend to bring up so i knew i was bored and didnt go ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'DonnieWahlberg Canada too Haha I know U were already here recently Im being greedy Sorry about the Australian dates ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Megadroid hit its first SL today ', 'sentiment': 0},\n",
       " {'text': 'MakeupAddict88 girl I didnt get it ', 'sentiment': 0},\n",
       " {'text': 'last finalll ', 'sentiment': 1},\n",
       " {'text': 'Doing devoz God really knows how to comfort me Wow Have no fear ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Ok I give up tweets are not working on my Fan Page ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Checking out at 10pm gotta be at the airport by 11pm Then sit at the airport for 3hours yeeiii not really happy bout that ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'ugh the work week has started ', 'sentiment': 0},\n",
       " {'text': 'gymclass Ooh that does sound useful Only three days to go and Ill be able to do that ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'missed stealingoneal at the hifi waaa they shouldve opened the doors earlier ah well see you at your next melbourne gig boys haha',\n",
       "  'sentiment': 0},\n",
       " {'text': 'ToysLogic took down their 18 Touhou Project preorders Guess Ill have to preorder from JList for 10 dollars more per figure ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Happy muthaths day to all moms I salute you ', 'sentiment': 1},\n",
       " {'text': 'meluka77 I will let you know when they are on sale ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'LadyHeatherBug well Milan is not so charming like Venice bur we got a bunch of good spots and its the best if you like shopping ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'lpetch i know i know thats why iam watchin wizards lmao',\n",
       "  'sentiment': 1},\n",
       " {'text': 'ffolliet Wine at 430 First cohort of BMS students finishing their degree ',\n",
       "  'sentiment': 1},\n",
       " {'text': ' Sunny smiley music ftw The Black Keys quotAct nice and gentlequot httptwtfm137436',\n",
       "  'sentiment': 1},\n",
       " {'text': 'The screen just went black and now theres only sound ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'ellehwho the 2009 one it sucks but i want to see people get killed and it was first on the list psycho',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Aprilsunincuba STOP FLAUNTING YOUR VIEWING I HAVE TO STUDY ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Quero ir no show do moptop ', 'sentiment': 0},\n",
       " {'text': 'Just waited 20 mins at the eye Drs to be told I need to reschedule ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'davidpeto amazing news Well done and happy holiday ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'I havent time ', 'sentiment': 0},\n",
       " {'text': 'Jeddidiah wish I was there no one wanted to do the drive with me and I didnt get off work til 8 ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'I am wondering if Carls JR took away their Kentucky Bourbon burger ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'WHAT WILL YOU DO IF YOUR FRIEND IS HAVING AN AFFAIR AND HIS WIFE IS ALSO YOUR FRIEND ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Spent 12 hour longer home before heading back for the Student service encouraging words from FlowerDust a little more refreshed ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'RachellNikole Thanks for the followfriday Our moms been out of town so we just now saw it ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'CyranDorman Those toys look awesome dont they Perfect little pieces of design and fun ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Jayman888 the bigfanfriday is great picked up amp finding loads 2 follow Woopwoop ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Hanging out with jonathanmead manvsdebt Yukai Chou gregorygo need a business idea Hit us up ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'tonibrain husky I had to give mine away but they went to my nanna so theyre all pansy and sooky now all they do is sleep and cuddle',\n",
       "  'sentiment': 0},\n",
       " {'text': ' mel I really should not be laughing at that but well couldnt help myself ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'amyrachel1911 haha thank you ', 'sentiment': 1},\n",
       " {'text': 'SoulTapestry Totally ', 'sentiment': 1},\n",
       " {'text': 'LesleyChang ah too bad sorry to hear the right fit will come along',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Nana says weve been doing a lot of eating during their visitwelcome to Richmond City of a thousand great places to stuff your face ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'cellytwits Iquotm sorry anything I can do to help', 'sentiment': 0},\n",
       " {'text': 'Dont feel good ', 'sentiment': 0},\n",
       " {'text': 'does anyone have Mad Season or More Than You Think You Are albums by matchbox twenty i cant find mine and im missing them terribly ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'chriswhite65 I know Useful if mugged though surely Product description 95 metal 4 cotton 1 silk ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'That being said starting next week I wont be on Twitter as much as I am doing so right now Maybe not even for chuckmemondays ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Whats a better way to start the day than playing Singstar D Attending my cousins baby sons 1 month dinner tonight Cant wait D',\n",
       "  'sentiment': 1},\n",
       " {'text': 'GlItCh017 but im not getting them on my phone ', 'sentiment': 0},\n",
       " {'text': 'KenzieWattie I FOUND YOUUUUUUUU Lovveyou Hubby xx', 'sentiment': 1},\n",
       " {'text': 'Dannymcfly hey yu should serious come to cyprus as youd make alot opf people very happy and hey me and kels will take yu clubbing lt3',\n",
       "  'sentiment': 1},\n",
       " {'text': 'sharayray I knew you were up to something ', 'sentiment': 1},\n",
       " {'text': 'dianadhevi oh well yeah its my fault I live in an awesome place ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Little boys with their mothers make me melancholy ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'cleaning ', 'sentiment': 1},\n",
       " {'text': 'Trolly hop and vodka extra dirty martinis are the greatest Especially when I get to see old friends Love it ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'omg i just seen like 15 seconds of the new moon trailer it waz awesome cant wait 2 c the movie',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Marco just left for work Feeling nervous and sad to leave him for the weekend Im going to miss him a lot ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'madeofhoney1 k ill make sure u are i wish i could bring u a cheeseburger wut are u working on ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Silverahnia now hold up I AM a gold digger LOL That goes for whoever Im dealing with we have to be equals or you better ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'yeah old time plan i dont even know why i agreed ', 'sentiment': 0},\n",
       " {'text': 'Mr Fluff has gone to snuggle in the great cloud bedding in the sky Funny how such a small chap can leave such a big hole in my life ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'i think i need a new seat for my bike cuz the one i have now hurts my ass ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'popstarmagazine httptwitpiccom5fdtz aww thats cute shes looking really pretty ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Enjoyed Mothers day with my momma and the ones I love Hope everyone had a good weekend I hate Mondays ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'I took Bentley on his first walk today ', 'sentiment': 1},\n",
       " {'text': 'stupid teacher took my fone ', 'sentiment': 0},\n",
       " {'text': 'US VISA approved Flyin next month Hope to do some serious research in Aerospace ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'westeross I guess the word tired implies you were unsuccessful ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Carolke Thanks I wish iI was there too ', 'sentiment': 1},\n",
       " {'text': 'KingBroly If course not but it still doesnt answer the exclusivity question for me anyways ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'this1kat meow', 'sentiment': 0},\n",
       " {'text': 'BIGMITCH05 Hope you had a good time Im a sad little girl today ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'finalising annual report for 2008 Ugh ', 'sentiment': 0},\n",
       " {'text': 'mdstacy11 haha Thanks Youre pretty awesome yourself Im so glad you came over last night and I hope you have a great weekend ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Ugh Up too early I jus went to sleep On another note why the heck is rain in the forecast EVERYWHERE For the whole week SS',\n",
       "  'sentiment': 0},\n",
       " {'text': 'mileycyrus TMNT is awesome power rangers is waaaaaay better though ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'jelleybean13 omg me too she died that same day she saw the movie ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'woooot i have a tanline finally ', 'sentiment': 1},\n",
       " {'text': 'giving Ms DFish all pennies and a dime for my report card I feel fairly evil lol',\n",
       "  'sentiment': 1},\n",
       " {'text': 'hair n makeup for work am fed up of working', 'sentiment': 0},\n",
       " {'text': 'Happy Birthday captainoneliner Have a great day dear ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'pavlovlita Hehehe di daerah Bendhill gitu say Dpn RS yg gede tuh apa yahaku lupa namanya Mintohardjo yah Hihi a must try ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'specialk2535 Get 100 followers a day using wwwtweeterfollowcom Once you add everyone you are on the train or pay vip ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Truly Madly Deeply Cascada Makes me wanna jump and smilee i love youu',\n",
       "  'sentiment': 1},\n",
       " {'text': 'NLiukin we love you to Nastia If I were a teen Id vote for ya but it wont let me ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Gone grappling pound em', 'sentiment': 1},\n",
       " {'text': 'AaRouls Hey check out my Top Ten signs your mom is a cougar on my twitter page There funny ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Day 3 with no ac temperatures above 90 and resulting migraines Landlord not cooperating despite lease provisions Never been so upset ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'LLCOOLDAVE BWAHA Oops Thats the New Orleans ribbing sessions coming out of melol Let me stop before my future child looks like Yoda ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'samcivilised Aww man i wish i was going to alton towers tomorrow ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'welshrob87 well done i forgot to enter ', 'sentiment': 0},\n",
       " {'text': 'Im sad I couldnt get as much videos done before I leave Not taking my laptop with meIm going to miss my channel so much ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'jam sesh cancelled ', 'sentiment': 0},\n",
       " {'text': 'ndarie sam question here I support iran election but I dont wanna be an ogre forever ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Shontelle Layne awhh glad to hear ur enjoyin dublin ill be beomin to see u and beyonce on wednesday in dublin cannot wait xx',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Hey I need 1 more follower to reach 1000 How cool Anyway it only matters if I can really be friends with all of you Shout out more ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'hasyya Haha yeah they do I think Im heading out in a bit to get some ice cream ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'Janetdawson2009 Hey I know you reasonably so I know you werent condoning it ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'DrLisaTurner I was going to attend but find I have an appointment at the dentists Hope youll be doing another or record this one',\n",
       "  'sentiment': 0},\n",
       " {'text': 'Anthony y Tony Hey ', 'sentiment': 1},\n",
       " {'text': 'its only 8 pm in cali ', 'sentiment': 0},\n",
       " {'text': 'threadbanger that is so far away from me Us canucks need some love to ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'mz Karen Guess what numbers packed already ', 'sentiment': 0},\n",
       " {'text': 'Damn I see I have to do my homework for Monday today already Pff how to spoil a Saturday ',\n",
       "  'sentiment': 0},\n",
       " {'text': 'I dont feel well ', 'sentiment': 0},\n",
       " {'text': 'Gotta love that sexy British accent ', 'sentiment': 1},\n",
       " {'text': 'rents are going in two days to vancouver ', 'sentiment': 1},\n",
       " {'text': 'KrisAllenmusic i think im having a last song syndrome with your song quotno boundariesquot your version is so good ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'mknisely awww man youre making me want Mexican food and Im supposed to be avoiding it ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'You tucked me in turned out the light kept me safe and sound at night little girls depend on things like that Miley Cyrus x ',\n",
       "  'sentiment': 1},\n",
       " {'text': 'I want to listen to my zune but I cant find my head phones ',\n",
       "  'sentiment': 0}]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "bb758dba-978b-4134-9ac3-a6ddfdc96a3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alberto Navarro\\anaconda3\\envs\\env2\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1468: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.8168168168168167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "def get_sentiment_list(texts_with_labels):\n",
    "    predicted_sentiments = []  # Lista para almacenar las etiquetas de sentimiento generadas por el modelo\n",
    "    true_sentiments = []  # Lista para almacenar las etiquetas de sentimiento reales\n",
    "\n",
    "    for item in texts_with_labels:\n",
    "        text = item[\"text\"]\n",
    "        true_sentiment = item[\"sentiment\"]\n",
    "\n",
    "        # Generar etiquetas de sentimiento (puedes mantener tu código existente aquí)\n",
    "        input_ids = tokenizer.encode('sentiment: ' + text + '</s>', return_tensors='pt')\n",
    "        output = model.generate(input_ids=input_ids, max_length=2)\n",
    "        dec = [tokenizer.decode(ids, skip_special_tokens=True) for ids in output]\n",
    "        predicted_sentiment = dec[0]\n",
    "        \n",
    "        predicted_sentiment = 1 if predicted_sentiment == \"positive\" else 0\n",
    "\n",
    "        predicted_sentiments.append(predicted_sentiment)\n",
    "        true_sentiments.append(true_sentiment)\n",
    "\n",
    "    return predicted_sentiments, true_sentiments\n",
    "\n",
    "predicted_sentiments, true_sentiments = get_sentiment_list(texts_with_labels)\n",
    "\n",
    "# Calcula el F1-score para comparar las etiquetas reales con las predichas\n",
    "f1 = f1_score(true_sentiments, predicted_sentiments, average='binary')\n",
    "\n",
    "print(\"F1-score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
